<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Plausible Knowledge Notation (PKN)</title>
  <script async class="remove" src="https://www.w3.org/Tools/respec/respec-w3c"></script>
  <script class="remove">
    var respecConfig = {
      shortName: "chunks",
      specStatus: "CG-DRAFT",
      noRecTrack: true,
      format: "markdown",
      edDraftURI: "https://w3c.github.io/cogai/",
      editors:  [
        {
          name: "Dave Raggett",
          company: "W3C",
          companyURL: "https://www.w3.org/",
          w3cid: "2682"
        }
      ],
      group: "cogai",
      github: {
        repoURL: "https://github.com/w3c/cogai/",
        branch: "master"
      },
      localBiblio: {
        "COLLINS": {
          title: "The logic of plausible reasoning: A core theory",
          year: 1989,
          publication: "Cognitive Science, 13(1), 1–49",
          href: "https://psycnet.apa.org/record/1989-38822-001",
          authors: [
            "Collins, A.",
            "Michalski, R."
          ]
        },
        "ARGUMENTATION": {
          title: "Argument and Argumentation",
          year: 2023,
          href: "https://plato.stanford.edu/entries/argument/"
        },
        "TOULMIN": {
          title: "The Uses of Argument",
          year: 1958,
          publication: "Cambridge University Press, ISBN 0-521-53483-6",
          href: "https://assets.cambridge.org/97805218/27485/sample/9780521827485ws.pdf",
          authors: [
            "Stephen Toulmin"
          ]
        },
        "WALTON": {
          title: "Argument Schemes for Presumptive Reasoning",
          year: 1996,
          publication: "Routledge, ISBN 9780805820720",
          href: "https://www.routledge.com/Argumentation-Schemes-for-Presumptive-Reasoning/Walton/p/book/9780805820720",
          authors: [
            "Douglas Walton"
          ]
        },
        "ASPIC+": {
          title: "ASPIC-END: Structured Argumentation with Explanations and Natural Deduction",
          year: 2018,
          href: "https://homepages.abdn.ac.uk/n.oren/pages/TAFA-17/papers/TAFA-17_paper_15.pdf",
          authors: [
          	"Jérémie Dauphin",
          	"Marcos Cramer"
          ]
        },
        "AIF": {
          title: "Argument Interchange Format (AIF)",
          year: 2011,
          href: "http://www.arg-tech.org/wp-content/uploads/2011/09/aif-spec.pdf"
        },
        "HAHN": {
          title: "The rationality of informal argumentation: A Bayesian approach to reasoning fallacies",
          year: 2007,
          href: "https://psycnet.apa.org/record/2007-10421-007",
          authors: [
          	"Ulrike Hahn",
          	"Mike Oaksford"
          ]
        },
        "FUZZY SETS": {
          title: "Fuzzy Sets",
          year: 1965,
          publication: "Information and Control, volume 8, 338-353 (1965)",
          href: "https://www.scribd.com/document/269570502/Zadeh-L-A-Fuzzy-Sets-1965",
          authors: [
            "Lotfi Zadeh"
          ]        },
        "IEEE-754-2019": {
          title: "IEEE 754-2019: IEEE Standard for Floating-Point Arithmetic. Institute of Electrical and Electronic Engineers, New York (2019)"
        },
        "PKN-demo": {
          title: "Demo for plausible reasoning and argumentation",
          href: "https://www.w3.org/Data/demos/chunks/reasoning/",
          authors: [
            "Dave Raggett"
          ]
        }
      }
    };
  </script>
</head>
<body>
  <section id="abstract">
    <p>This specification defines the plausible knowledge notation (PKN) as a lightweight syntax for expressing imperfect knowledge, i.e. knowledge that is uncertain, imprecise, incomplete and inconsistent. PKN was inspired by the work of Alan Collins and co-workers in the 1980s, see [[COLLINS]]. PKN consists of queries, properties, relations, implications and analogies. PKN embraces fuzzy scalars, fuzzy modifiers and fuzzy quantifiers. PKN statements can be associated with metadata that models sub-symbolic knowledge corresponding to intuitive notations such as the strength of a statement, and the typicality of a sub-class in respect to its parent class.</p>
  </section>

  <section id="sotd">
    <p>This document is at early stages of development. Feedback is welcome through <a href="https://github.com/w3c/cogai/issues">GitHub issues</a> or on the <a href="mailto:public-cogai@w3.org">public-cogai@w3.org</a> mailing-list (with <a href="https://lists.w3.org/Archives/Public/public-cogai/">public archives</a>).</p>
  </section>
  
  <section class="informative">
    <h2>Introduction</h2>
    <p>This specification defines a notation and model for imperfect knowledge, such as everyday knowledge that is uncertain, imprecise, incomplete and inconsistent. The approach is modelled on human argumentation, something that a long line of philosophers have investigated since the days of Ancient Greece. Traditional logic assumes perfect knowledge and provides mathematical proof for entailments. Unfortunately, knowledge is rarely perfect, but is nonetheless amenable to reasoning using guidelines for effective arguments.  As an example consider the statement: <em>if it is raining then it is cloudy</em>.  This is generally true, but you can also infer that it is somewhat likely to be raining if it is cloudy. This is plausible based upon your rough knowledge of weather patterns. In place of logical proof, we have multiple lines of argument for and against the premise in question just like in courtrooms and everyday reasoning.</p>
    
    <figure id="inferences">
      <img src="images/inferences.png" alt="" style="width:60%"/>
      <figcaption>Inferring likely properties and relations across relations</figcaption>
    </figure>
    
    <p>The above figure shows how properties and relations involving a class may be likely to apply to a sub-class as a specialisation of the parent class. Likewise, properties and relations holding for a sub-class may be likely to apply to the parent class as a generalisation. The likelihood of such inferences is influenced by the available metadata. Inferences can also be based on implication rules, and analogies between concepts with matching structural relationships. PKN further supports imprecise concepts:</p>
    
    <ul>
       <li>fuzzy terms, e.g. <em>cold, warm</em> and <em>hot</em>, which form a scalar range with overlapping meanings.</li>
       <li>fuzzy modifiers, e.g. <em>very</em> old, where such terms are relative to the context they apply to.</li>
       <li>fuzzy quantifiers, e.g. <em>few</em> and <em>many</em>, for queries akin to SPARQL.</li>
    </ul>
    
    <p>For a web-based demonstrator, see [[PKN-demo]]. PKN can be used to support question and answering over knowledge graphs, and informed decision making based upon balanced arguments.</p>
    
    <section>
      <h3>Relationship to Previous Work</h3>
      
      <p>The Stanford Encyclopedia of Philosophy entry on argument and argumentation [[ARGUMENTATION]] lists five types of arguments: deduction, induction, abduction, analogy and fallacies. Argumentation can be <em>adversarial</em> where one person tries to beat down another, or <em>cooperative</em> where people collaborate on seeking a better joint understanding by exploring arguments for and against a given supposition. The latter may further choose to focus on developing a consensus view, with the risk that argumentation sometimes stimulate group polarisation as people's views become further entrenched.</p>
      
      <p>Studies of argumentation have been made by a long line of philosophers dating back to Ancient Greece, e.g. Carneades and Aristotle.  More recently, logicians such as Frege, Hilbert and Russell were primarily interested in mathematical reasoning and argumentation. Stephen Toulmin subsequently criticised the presumption that arguments  should be formulated in purely formal deductive terms [[TOULMIN]]. Douglas Walton extended tools from formal logic to cover a wider range of arguments [[WALTON]]. Ulrike Hahn, Mike Oaksford and others applied Bayesian techniques to reasoning and argumentation [[HAHN]], whilst Alan Collins applied a more intuitive approach to plausible reasoning [[COLLINS]].</p>
      
      <p>Formal approaches to argumentation such as [[ASPIC+]] build arguments from axioms and premises as well as strict and defeasible rules. Strict rules logically entail their conclusions, whilst defeasible rules create a presumption in favour of their conclusions, which may need to be withdrawn in the light of new information. Arguments in support of, or counter to, some supposition, build upon the facts in the knowledge graph or the conclusions of previous arguments. Preferences between arguments are derived from preferences between rules with additional considerations in respect to consistency. Counter arguments can be classified into three groups. An argument can:</p>
      <ul>
      <li><em><strong>undermine</em></strong> another argument when the conclusions of the former contradict premises of the latter.</li>
      <li><em><strong>undercut</em></strong> another argument by casting doubt on the link between the premises and conclusions of the latter argument.</li>
      <li><em><strong>rebut</em></strong> another argument when their respective conclusions can be shown to be contradictory.</li>
      </ul>
      
      <p>[[AIF]] is an ontology intended to serve as the basis for an interlingua between different argumentation formats. It covers <em>information</em> (such as propositions and sentences) and <em>schemes</em> (general patterns of reasoning). The latter can be used to model lines of reasoning as argument graphs that reference information as justfication. The ontology provides constraints on valid argument graphs, for example:</p>
	  <aside class="example">
      <dl>
      <dt><em><strong>Scheme for Argument from Expert Opinion</em></strong>:</dt> 
      <dd><em>premises</em>: E asserts that A is true (false), E is an expert in domain D containing A; <em>conclusion</em>: A is true (false); <em>presumptions</em>: E is a credible expert, A is based on evidence; <em>exceptions</em>: E is not reliable, A is not consistent with what other experts assert.</dd>
      </dl>
      </aside>

      <p>Conflict schemes model how one argument conflicts with another, e.g. if an expert is deemed unreliable, then we cannot rely on that expert's opinions. Preference schemes define preferences between one argument and another, e.g. that expert opinions are preferred over popular opinions. The AIF Core ontology is available in a number of standard ontology formats (RDF/XML, OWL/XML, Manchester OWL Syntax).</p>

      <p>PKN defines a simple notation and model for imperfect knowledge. Arguments for and against a supposition are constructed as chains of plausible inferences that are used to generate explanations. PKN draws upon Alan Collins core theory of plausible reasoning in respect to statement metadata corresponding to intuitions/gut feelings based upon prior experience. This is in contrast to Bayesian techniques that rely on the availability of rich statistics, which are unavailable in many everyday situations.</p>
    </section>
  </section>

<section id="conformance">
    <p>The grammatical rules in this document are to be interpreted as described in [[[RFC5234]]] [[RFC5234]].</p>
    <section>
      <h3>Conformance classes</h3>
      <p>Conformance to this specification is defined for four conformance classes:</p>
      <dl>
        <dt><dfn>PKN document</dfn></dt>
        <dd>A serialization of a [=PKN graph=] as a file. A [=PKN document=] is conformant to this specification if it follows the grammar described in <a href="#grammar"></a>.</dd>
        <dt><dfn>Authoring tool</dfn></dt>
        <dd>An application that writes a [=PKN document=]. An [=authoring tool=] is conformant to this specification if it writes conforming [=PKN documents=].</dd>
        <dt><dfn>Parser</dfn></dt>
        <dd>A [=parser=] transforms a [=PKN document=] into another representation. A [=parser=] is conformant to this specification if it can do so for any conforming [=PKN document=].</dd>
        <dt><dfn>Rule engine</dfn></dt>
        <dd>A processing application that operates on PKN statements. A [=rule engine=] is conformant to this specification if it follows the algorithms defined in Section <a href="#reasoning"></a>.</dd>
      </dl>
    </section>
</section>

<section id="data-types">
  <h2>Data Types</h2>
  
  <p>PKN documents use the following restricted set of data types. See <a href="#grammar"></a> for a formal definition of their serialization.</p>

    <p>A <dfn>number</dfn> represents a double-precision 64-bit format value as specified in the IEEE Standard for Binary Floating-Point Arithmeticis [[IEEE-754-2019]]. It is serialized in base 10 using decimal digits, following the same grammar as <a data-cite="RFC8259#section-6">numbers in JSON</a> [[RFC8259]].</p>
    
    <p>A <dfn>name</dfn> is a string that can include letters, digits, period, hyphen, underscore and slash characters, and that cannot be interpreted as a [=number=].</p>
</section>

<section id="statements">
  <h2>PKN Statements</h2>
  
  <p>PKN supports several kinds of statements as defined below.</p>

  <section id="metadata">
    <h3>Statement MetaData</h3>
    
    <p>Property, relation and implication statements optionally have a scope and a set of parameters. The scope is one or more names that indicate the context in which the statement applies, e.g. ducks are similar to geese in that they are birds with relatively long necks when compared to other bird species. Each parameter consists of a name and a value. Parameters represent prior knowledge as an informal qualitative feeling. Predefined parameters include:</p>
    
    <dl>
    <dt><dfn>certainty</dfn></dt>
    <dd>The confidence in the associated statement being true.</dd>
    <dt><dfn>strength</dfn></dt>
    <dd>The confidence in the consequents being true for an implication statement, i.e. the likelihood of the consequents holding if the antecedents hold.</dd>
    <dt><dfn>inverse</dfn></dt>
    <dd>The confidence in the antecedents being true when using an implication statement in reverse, i.e. the likelihood of the antecedents holding if the consequents hold.</dd>
    <dt><dfn>typicality</dfn></dt>
    <dd>The likelihood that a given instance of a class is typical for that class, e.g. that a Robin is a typical song bird.</dd>
    <dt><dfn>similarity</dfn></dt>
    <dd>The extent to which one thing is similar to another, e.g. the extent that they have some of the same properties.</dd>
    <dt><dfn>dominance</dfn></dt>
    <dd>The relative importance of an instance of a class as compared to other instances. For a country, for instance, this could relate to the size of its population or the size of its economy.</dd>
    </dl>
    
    <p>See section [[[#reasoning]]] for the role of statement parameters in argumentation.</p>
    
    <p class="issue">Where should we describe how names can be used for graphs and statements?</p>
    
     <p class="issue">Need to explain the relation to existing argumentation systems, along with formalisms such as AIF and ASPIC, together with questions around correctness, complexity and semantics. Note the need to explain why formal semantics is challenging for imperfect knowledge.</p>
  </section>

  <section id="properties">
    <h3>Property Statements</h3>
    
    <p>These are used either to declare properties of things, or as conditions and actions in implication and query statements. A property statement has four parts: the descriptor, an argument, an operator and a referent. Here is an example:</p> 
    
    <aside class="example" title="Property Statements">
      <pre><code>flowers of Netherlands includes daffodils, tulips (certainty high)</code></pre>
      <p>Here <em>flowers</em> is the descriptor, <em>Netherlands</em> is the argument, <em>includes</em> is the operator, and <em>daffodils, tulips</em> is the referent. In other words, daffodils and tulips are amongst the flowers found in the Netherlands. The meta data indicates that this statement has a high certainty.</p>
    </aside>
    
    <p>The following operators are predefined:</p>
    <dl>
    <dt>includes</dt>
    <dd>This implies that the property is not limited to the given referent.</dd>
    <dt>excludes</dt>
    <dd>This implies that the property doesn't hold for the given referent.</dd>
    <dt>is</dt>
    <dd>This implies that the property is limited to the given referent.</dd>
    </dl>
    
    <p>Note: variables are only permitted within properties that appear as conditions or actions in implication statements or query statements.</p>
    
    <p class="issue">Should the the predefined operators include "<code>is not</code>"?</p>
  </section>

  <section id="relations">
    <h3>Relation Statements</h3>
    
    <p>Relation statements have three parts: the subject, the relationship, and the object. Relations can be used on their own, or as part of implication and query statements. Here are some examples:</p>
    
    <aside class="example" title="Relation Statements">
      <pre><code>tulips kind-of temperate-flowers
Belgium similar-to Netherlands for latitude
younger-than equivalent-to less-than for age</code></pre>
      <p>The first example declares that tulips are a kind of flowers found in countries with temperate climates. The last two examples specify a scope for which the relation holds.</p>
    </aside>

    <p>Note: variables are only permitted within relations that appear as conditions or actions in implication statements or query statements.</p>
  </section>

  <section id="implications">
    <h3>Implication Statements</h3>
    
    <p>An implication statement defines one or more consequents, and one or more antecedents, which are properties or relations, and may include variables which are scoped to the implication statement. The consequents are evaluated as a conjunction of conditions. See section [[[#reasoning]]] for details. Here are some examples of implication statements:</p>
    
    <aside class="example" title="Implications Statements">
      <pre><code># rainy weather and cloudy conditions
weather of ?place includes rainy
	implies weather of ?place includes cloudy (strength high, inverse low)</code></pre>
      <p>This example has a single antecedent and a single consequent. Note the use of <code>?place</code> as a variable, and metadata for the confidence in using the statement for forward and backward inferences.</p>
    </aside>
  </section>

  <section id="analogies">
    <h3>Analogy Statements</h3>
    <p> These relate two pairs of concepts where each pair stands as an analogy for the other pair.</p>
    
    <aside class="example" title="Analogy Statements">
      <pre><code>leaf:tree::petal:flower</code></pre>
      <p>In this example, a leaf is a part of a tree, whilst a petal is part of a flower. The analogy holds because both pairs of concepts involve the <em>part-of</em> relation.</p>
    <p>Note that concepts can be replaced by variables when you want to query for a concept that fits the implicit analogy, as shown below.</p>
    <pre><code>dog:puppy::cat:?</code></pre>
    </aside>
  </section>

  <section id="queries">
    <h3>Query Statements</h3>
    <p>These have a <em>quantifier</em>, a <em>variable</em>, an optional <em>where clause</em>, and a required <em>from clause</em>. Variables are scoped to the query statement. The where and from clauses involve a conjunction of one or more conditions, which are properties or relations. The conditions for the from clause are evaluated against the PKN statement graph. The conditions for the where clause are evaluated against the matches found with the from clause. The tests relate to the variable bindings.</p>
    
    <aside class="example" title="Query Statements">
      <pre><code>which ?x where ?x is-a person and age of ?x is very:old
count ?x where age of ?x greater-than 20 from ?x is-a person
few ?x where color of ?x includes yellow from ?x kind-of rose</code></pre>
      <p>The first query lists the people in the PKN graph who are considered to be very old. See section [[[#fuzzy]]]. The second query counts the number of people older that 20. The third query checks whether there are few yellow roses in the PKN graph.</p>
    </aside>
    
    <p>Queries can use the following quantifiers:</p>
    
    <dl>
    <dt><dfn>no</dfn></dt>
    <dd>Tests that the PKN graph has no matches for the conditions in the <em>from clause</em>.</dd>
    <dt><dfn>all</dfn></dt>
    <dd>Tests that the conditions for the  <em>where clause</em> hold for all of the matches for the conditions in the <em>from clause</em>.</dd>
    <dt><dfn>any</dfn></dt>
    <dd>Tests that the conditions for the  <em>where clause</em> hold for at least one of the matches for the conditions in the <em>from clause</em>.</dd>
    <dt><dfn>few</dfn></dt>
    <dd>Tests that the conditions for the  <em>where clause</em> hold for few of the matches for the conditions in the <em>from clause</em>.</dd>
    <dt><dfn>many</dfn></dt>
    <dd>Tests that the conditions for the  <em>where clause</em> hold for many of the matches for the conditions in the <em>from clause</em>.</dd>
    <dt><dfn>most</dfn></dt>
    <dd>Tests that the conditions for the  <em>where clause</em> hold for most of the matches for the conditions in the <em>from clause</em>.</dd>
    <dt><dfn>which</dfn></dt>
    <dd>Yields the list of variable bindings that satisfy the conditions.</dd>
    <dt><dfn>count</dfn></dt>
    <dd>Yields the length of the list of variable bindings that satisfy the conditions.</dd>
    </dl>
    
    <p>Note that few, many and most are imprecise terms and can be defined in terms of the length of the list of variable bindings that satisfy the conditions. <code>few</code> signifies a small number, <code>many</code> signifies a large number, and <code>most</code> signifies that the number of bindings for the <em>where clause</em> is a large proportion of the number of bindings for the <em>from clause</em>.</p>
    
    <p class="issue">Is it necessary to specify few, many and most in more detail?</p>
  </section>
</section>

<section id="fuzzy" class="informative">
	<h2>Fuzzy Knowledge</h2>
	
	<p>Plausible reasoning subsumes fuzzy logic as expounded by Lotfi Zadeh in his 1965 paper on fuzzy logic, see [[FUZZY SETS]]. Fuzzy logic includes four parts: fuzzification, fuzzy rules, fuzzy inference and defuzzification.</p>
	<p>Fuzzification maps a numerical value, e.g., mapping a temperature value into a fuzzy set, where a given temperature could be modelled as 0% cold, 20% warm and 80% hot. This involves transfer functions for each term, and may use a linear ramp or some kind of smooth function for the upper and lower part of the term’s range.</p>
	<p>Fuzzy rules relate terms from different ranges, e.g., if it is hot, set the fan speed to fast, if it is warm, set the fan speed to slow. The rules can be applied to determine the desired fan speed as a fuzzy set, e.g., 0% stop, 20% slow and 80% fast. Defuzzification maps this back to a numeric value.</p>
	<p>Fuzzy logic works with fuzzy sets in a way that mimics Boolean logic in respect to the values associated with the terms in the fuzzy sets. Logical AND is mapped to selecting the minimum value, logical OR is mapped to selecting the maximum value, and logical NOT to one minus the value, assuming values are between zero and one.</p>
	<p>Plausible reasoning expands on fuzzy logic to support a much broader range of inferences, including context dependent concepts, and the means to express fuzzy quantifiers and modifiers.</p>
	
	<section>
	    <h2>Scalar ranges</h2>
	    <p>Some concepts are characterised by a value that lies in a range. Examples include temperature, age and climate. The temperature of a room may be described as cold, warm or hot. Such terms are imprecise and lack a formally agreed definition. Moreover, the meaning may depend on the context. Someone who is 60 years old will have a very different notion of what "old" means compared to that of an eight year old child.</p>
	    
	    <p>The choice of scales for a range may depend on the application. Here are some examples for different types of climate:</p>
	    
	    <ul>
	    <li>dry, temperate, continental and polar</li>
	    <li>polar, temperate, arid, tropical, mediterranean, mountain</li>
	    <li><em>Hot:</em> equatorial, tropical, subtropical; <em>Temperate:</em>  mediterranean. chinese, oceanic, continental; <em>Cold:</em> polar, highland</li>
	    </ul>
	    
	    <p>Each of these terms is associated with typical weather patterns for that climate, e.g. in cities like Shanghai, Buenos Aires, Sydney, and Hong Kong there is a so called Chinese climate with mild winters and humid summers with tropical rain.</p>
	    
	    <p>This can be modelled using the <em>range</em> property along with a <em>scope</em>. The value of this property is a list of climates. These climates can be treated as arguments for properties that characterise that climate, e.g. in terms of their span on a numerical scale.</p>
	    
	    <p>Here is an example for <em>age</em> that lists terms for describing someone's age, along with the associate span in years:</p>
	    
    <aside class="example" title="Scalar Ranges">
      <pre><code>range of age is infant, child, adult for person
age of infant is 0, 4 for person
age of child is 5, 17 for person
age of adult is 18, age-at-death for person</code></pre>
      <p>.</p>
    </aside>
	    
	</section>
	

</section>

<section id="documents">
  <h2>PKN Documents</h2>
  
  <p>A PKN document is a sequence of PKN statements.</p>
  
  <section>
    <h3>PKN Graphs</h3>
    <p>A <dfn data-lt="pkn-graph">PKN Graph</dfn> is an abstract representation of a PKN document as a graph in which statement are the vertices and names are the edges.</p>
  </section>
  
  <section id="grammar">
    <h3>PKN Grammar</h3>
    <p>A [=PKN document=] MUST follow the grammar defined below.</p>

    <pre><code class="abnf" data-include="grammar/pkn.ebnf" data-include-format="text"></code></pre>

    <p>Comments start with '#' and continue to the end of the current line or the end of the file, whichever comes first. White space is permitted between tokens. One exception is between '?' and the name token for a variable. Another exception is between the sign ('+' and '-') and the digits that form a number.</p>
    
    <p class="issue">Should the grammar notation be switched from EBNF to ABNF for consistency with W3C practice, noting that EBNF is easier to understand?</p>
  </section>  
  
  <section id="railroad-diagrams" class="informative">
    <h3>Railroad Diagrams</h3>
    
    <p>This section presents a visualisation of the grammar in the form of railroad diagrams. These diagrams are provided solely to make it easier to get an intuitive grasp of the syntax of each token.</p>
    
    <div data-include="grammar/pkn-rr.html" data-include-replace="true"></div>
  </section>  
  
  <section id="pkn-rdf" class="informative">
    <h3>PKN and RDF</h3>
  </section>  
</section>

<section id="reasoning">
  <h2>Plausible Reasoning and Argumentation</h2>
  
  <p>This section describes how PKN statements can be used to compute inferences along with their estimated certainty, as the basis for constructing arguments both for and against a given premise.</p>
  
  <section id="query-execution">
    <h3>Reasoning with Relations</h3>
  </section>  
  
  <section id="query-execution">
    <h3>Reasoning with Implications</h3>
  </section>  
  
  <section id="query-execution">
    <h3>Reasoning with Queries</h3>
  </section>  
  
  <section id="certainty">
    <h3>Estimating Certainty</h3>
  </section>  
  
  <section id="arguments">
    <h3>Assessing Multiple Lines of Argumentation</h3>
  </section>  
  
  <section id="explanations">
    <h3>Generating Explanations</h3>
  </section>  
  
</section>

</body>
</html>
